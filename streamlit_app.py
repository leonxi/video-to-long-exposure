# coding=utf-8
import streamlit as st
from PIL import Image
import cv2 as cv
import tempfile
from utils import MyImgUtils 

st.set_page_config(
    page_title="è§†é¢‘åˆæˆé•¿æ›å…‰ç…§ç‰‡",
    page_icon="ðŸ§Š",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'å¯»æ‰¾è½®å»“': 'https://find-image-contours.streamlit.app/'
    }
)

st.write("""
# ä»Žè§†é¢‘åˆæˆé•¿æ›å…‰ç…§ç‰‡
æ²¡æœ‰å•å, æ²¡æœ‰ç°åº¦æ»¤å…‰é•œ, ä½¿ç”¨æ‰‹æœºä¹Ÿèƒ½æ‹å‡º ___æ˜Ÿè½¨___ å’Œ ___ç€‘å¸ƒ___ æ‘„å½±ä½œå“, æ¥çœ‹çœ‹æ•ˆæžœå§
""")

st.write("""
## æ˜Ÿè½¨
""")

col1, col2 = st.columns(2)

video_file = open('samples/star-trails.mp4', 'rb')
video_bytes = video_file.read()

with col1:
    st.video(video_bytes, format="video/mp4", start_time=0)

image = Image.open('samples/star-trails.png')
with col2:
    st.image(image)

st.write("""
## ç€‘å¸ƒ
""")

col3, col4 = st.columns(2)

video_file3 = open('samples/waterfall.mp4', 'rb')
video_bytes3 = video_file3.read()

with col3:
    st.video(video_bytes3, format="video/mp4", start_time=0)

image3 = Image.open('samples/waterfall.png')
with col4:
    st.image(image3)

st.write("""
## å¼€å§‹åˆ›ä½œä½ çš„ä½œå“
""")

optioncol1, optioncol2 = st.columns(2)

with optioncol1:
    uploaded_file = st.file_uploader("ä¸Šä¼ å›ºå®šæœºä½æ‹æ‘„çš„è§†é¢‘æ–‡ä»¶", type=['mp4'])

with optioncol2:
    mode = st.radio(
    "é€‰æ‹©ç”Ÿæˆæ•ˆæžœ",
    ('æ˜Ÿè½¨', 'ç€‘å¸ƒ'), horizontal=True)

if uploaded_file is not None:
    data = uploaded_file.getvalue()
    st.video(data, format="video/mp4", start_time=0)

    # ä¸Šä¼ è§†é¢‘æ”¾å…¥OpenCVè¿›è¡Œå¤„ç†
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())

    videoCap = cv.VideoCapture(tfile.name)

    if videoCap.isOpened() == True:

        # åˆ†è¾¨çŽ‡
        width = int(videoCap.get(cv.CAP_PROP_FRAME_WIDTH))
        height = int(videoCap.get(cv.CAP_PROP_FRAME_HEIGHT))
        # å¸§çŽ‡
        fps = videoCap.get(cv.CAP_PROP_FPS)
        # æ€»å¸§æ•°
        frames = videoCap.get(cv.CAP_PROP_FRAME_COUNT)
        # ç¼–ç æ ¼å¼
        fourcc = int(videoCap.get(cv.CAP_PROP_FOURCC))

        start = st.slider(
            'é€‰æ‹©è§†é¢‘å¼€å§‹å¸§',
            0, int(frames), 0, step = 1)

        end = start + 255

        if end > frames:
            end = frames

        r, g, b = None, None, None
        r_avg, g_avg, b_avg = MyImgUtils.averager(), MyImgUtils.averager(), MyImgUtils.averager()
        if mode == "æ˜Ÿè½¨":
            r_avg, g_avg, b_avg = MyImgUtils.maxer(), MyImgUtils.maxer(), MyImgUtils.maxer()

        mergedResult = None
        ret, frame = videoCap.read()

        count = 1
        while ret: 

            # æŽ§åˆ¶å¤„ç†å¸§èŒƒå›´
            if start > count:
                ret, frame = videoCap.read()
                count += 1
                continue

            if end < count:
                break

            # Get the current RGB
            b_curr, g_curr, r_curr = cv.split(frame.astype("float"))
            r, g, b = r_avg(r_curr), g_avg(g_curr), b_avg(b_curr)

            ret, frame = videoCap.read()
            count += 1

        print("å¤„ç†ç»“æŸ")
        videoCap.release()
        mergedResult = cv.merge([b, g, r]).astype("uint8")

        toImage = Image.fromarray(cv.cvtColor(mergedResult, cv.COLOR_BGR2RGB))
        st.image(toImage)
else:
    st.video(video_bytes, format="video/mp4", start_time=0)

    st.image(image)
